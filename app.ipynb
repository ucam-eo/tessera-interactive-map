{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import ipyleaflet\n",
    "from ipyleaflet import (\n",
    "    TileLayer,\n",
    "    Map,\n",
    "    ImageOverlay,\n",
    "    CircleMarker,\n",
    "    LayersControl,\n",
    "    WidgetControl,\n",
    ")\n",
    "from ipywidgets import *\n",
    "from geotessera import GeoTessera\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from functools import partial\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "import rasterio\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "from rasterio.enums import Resampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "from interactive import utils, config, visualisation\n",
    "\n",
    "Config = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config defaults for lat_coords: [-0.1, 0.3] and lon_coords: [52.0, 52.2]\n",
      "Bounding box defined:\n",
      "┗ (52.00, -0.10) | ┓ (52.20, 0.30)\n"
     ]
    }
   ],
   "source": [
    "# -- 1. ROI DEFINITION --\n",
    "# This is in increments of 0.1, and requires at least a 0.1 by 0.1 deg bbox\n",
    "\n",
    "# update coordinates here, otherwise defaults will be used (South Cambridge)\n",
    "MIN_LON, MAX_LON = None, None\n",
    "MIN_LAT, MAX_LAT = None, None\n",
    "\n",
    "(MIN_LAT, MAX_LAT), (MIN_LON, MAX_LON) = utils.define_roi(\n",
    "    lat_coords=(MIN_LAT, MAX_LAT),\n",
    "    lon_coords=(MIN_LON, MAX_LON),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box defined:\n",
      "┗ (52.00, -0.10) | ┓ (52.20, 0.30)\n",
      "\n",
      "Searching for tiles in ROI: (-0.1, 52.0, 0.3, 52.2) for year 2024\n",
      "\n",
      "Found 15 tiles to merge.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24606495863c4bcc8f86d7c83cbdbde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tiles:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging all tiles...\n",
      "Shape of final embedding mosaic: (2853, 4791, 128)\n"
     ]
    }
   ],
   "source": [
    "# -- 2. FETCH AND MOSAIC RELEVANT TESSERA TILES --\n",
    "\n",
    "embedding_mosaic, mosaic_transform = utils.TesseraUtils().process_roi_to_mosaic(\n",
    "    lat_coords=(MIN_LAT, MAX_LAT),\n",
    "    lon_coords=(MIN_LON, MAX_LON),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated bounds: ((51.89743052830078, -0.20626269731868993), (52.202497982390696, 0.3060324910951864))\n",
      "\n",
      "Creating PCA-based visualization...\n",
      "Normalizing PCA components for display...\n",
      "PCA visualization created.\n",
      "Image overlay added to map\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6686d0bc77d94bb99cc56ac248ed9fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Basemap:', options=('Esri Satellite', 'Goog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- 3. VISUALISE AND PLACE TRAINING POINTS --\n",
    "\n",
    "mapping_tool = visualisation.InteractiveMappingTool(\n",
    "    MIN_LAT,\n",
    "    MAX_LAT,\n",
    "    MIN_LON,\n",
    "    MAX_LON,\n",
    "    embedding_mosaic,\n",
    "    mosaic_transform,\n",
    ")\n",
    "mapping_tool.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 4. CLASSIFICATION STAGE --\n",
    "\n",
    "# A global variable to hold the classification layer so we can remove it later\n",
    "classification_layer = None\n",
    "\n",
    "\n",
    "def on_classify_button_clicked(b):\n",
    "    global classification_layer\n",
    "\n",
    "    with output_log:\n",
    "        output_log.clear_output()\n",
    "\n",
    "        if len(training_points) < 2 or len(set(c for p, c in training_points)) < 2:\n",
    "            print(\n",
    "                \"ERROR: Please add at least two points from two different classes to train the model.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        print(\"Starting classification...\")\n",
    "        X_train, y_train = [], []\n",
    "\n",
    "        # Create a mapping from class names (e.g., 'Water') to integer labels (e.g., 0)\n",
    "        unique_class_names = sorted(list(set(name for point, name in training_points)))\n",
    "        class_index_map = {name: i for i, name in enumerate(unique_class_names)}\n",
    "        print(f\"Discovered classes for training: {unique_class_names}\")\n",
    "\n",
    "        # 2. --- PREPARE TRAINING DATA (THE KEY CHANGE) ---\n",
    "        print(f\"Mapping {len(training_points)} training points to pixel coordinates...\")\n",
    "\n",
    "        # Get mosaic dimensions from the global variable created in the previous cell\n",
    "        mosaic_height, mosaic_width, num_channels = embedding_mosaic.shape\n",
    "\n",
    "        for (lat, lon), class_name in training_points:\n",
    "            row, col = rasterio.transform.rowcol(mosaic_transform, lon, lat)\n",
    "            if 0 <= row < mosaic_height and 0 <= col < mosaic_width:\n",
    "                X_train.append(embedding_mosaic[row, col, :])\n",
    "                y_train.append(class_index_map[class_name])\n",
    "            else:\n",
    "                # This can happen if a user clicks just outside the reprojected mosaic area\n",
    "                print(\n",
    "                    f\"  - WARNING: Skipping point for '{class_name}' at ({lat:.4f}, {lon:.4f}) as it falls outside the mosaic's bounds.\"\n",
    "                )\n",
    "\n",
    "        if not X_train:\n",
    "            print(\"ERROR: None of the training points were inside the mosaic bounds.\")\n",
    "            return\n",
    "\n",
    "        # 3. --- TRAIN THE MODEL ---\n",
    "        print(f\"Training k-NN classifier on {len(X_train)} valid points...\")\n",
    "        # Use a sensible k, ensuring it's not larger than the number of samples\n",
    "        k = min(5, len(X_train))\n",
    "        model = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # 4. --- PREDICT ON THE ENTIRE MOSAIC ---\n",
    "        # print(\"Predicting on the full image... (this may take a moment)\")\n",
    "        # all_pixels = embedding_mosaic.reshape(-1, num_channels)\n",
    "        # predicted_labels = model.predict(all_pixels)\n",
    "        # classification_result = predicted_labels.reshape(mosaic_height, mosaic_width)\n",
    "\n",
    "        all_pixels = embedding_mosaic.reshape(-1, num_channels)\n",
    "        n_pixels = all_pixels.shape[0]\n",
    "        batch_size = 15000\n",
    "        predicted_labels = np.zeros(n_pixels, dtype=np.uint8)\n",
    "\n",
    "        # Use tqdm with total set to n_pixels and update it by batch size\n",
    "        with tqdm(total=n_pixels, desc=\"Classifying pixels\") as pbar:\n",
    "            for i in range(0, n_pixels, batch_size):\n",
    "                end = min(i + batch_size, n_pixels)\n",
    "                predicted_labels[i:end] = model.predict(all_pixels[i:end, :])\n",
    "                pbar.update(\n",
    "                    end - i\n",
    "                )  # update progress bar by number of processed pixels\n",
    "\n",
    "        classification_result = predicted_labels.reshape(mosaic_height, mosaic_width)\n",
    "\n",
    "        # Clean up the reshaped array\n",
    "        del all_pixels\n",
    "\n",
    "        # 5. --- VISUALIZE AND DISPLAY THE RESULT ---\n",
    "        print(\"Creating visualization of the classification result...\")\n",
    "\n",
    "        # Create a colormap for the final image using the same colors as the pins\n",
    "        color_list = [\n",
    "            get_or_assign_color_for_class(name) for name in unique_class_names\n",
    "        ]\n",
    "        cmap = mcolors.ListedColormap(color_list)\n",
    "        norm = mcolors.Normalize(vmin=0, vmax=len(unique_class_names) - 1)\n",
    "\n",
    "        # Apply the colormap to the integer-labeled result array\n",
    "        colored_result = cmap(norm(classification_result))\n",
    "\n",
    "        # Convert the numpy array to a PNG image in memory\n",
    "        buffer = io.BytesIO()\n",
    "        plt.imsave(buffer, colored_result, format=\"png\")\n",
    "        buffer.seek(0)\n",
    "        b64_data = base64.b64encode(buffer.read()).decode(\"utf-8\")\n",
    "        classification_data_url = f\"data:image/png;base64,{b64_data}\"\n",
    "\n",
    "        print(\"Displaying result on the map...\")\n",
    "        # If an old classification layer exists, remove it first\n",
    "        if classification_layer and classification_layer in m.layers:\n",
    "            m.remove_layer(classification_layer)\n",
    "\n",
    "        # Create the new ImageOverlay for the classification\n",
    "        classification_layer = ipyleaflet.ImageOverlay(\n",
    "            url=classification_data_url,\n",
    "            bounds=VIS_BOUNDS,\n",
    "            opacity=0.7,\n",
    "            name=\"Classification\",\n",
    "        )\n",
    "        m.add(classification_layer)\n",
    "\n",
    "        # Enable the clear button now that a layer exists\n",
    "        clear_classification_button.disabled = False\n",
    "        print(\"Classification complete.\")\n",
    "\n",
    "\n",
    "# Attach the function to the button's click event\n",
    "classify_button.on_click(on_classify_button_clicked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tessera-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
